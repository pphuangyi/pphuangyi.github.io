<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html">About&nbsp;me</a></div>
<div class="menu-item"><a href="res.html" class="current">Research</a></div>
<div class="menu-item"><a href="https://www.bnl.gov/world/">Brookhaven&nbsp;National&nbsp;Lab</a></div>
<div class="menu-item"><a href="https://www.bnl.gov/compsci/">BNL&nbsp;CSI</a></div>
</td>
<td id="layout-content">
<h1>Publications</h1>
<ul>
<li><p><i>Dmitrii Torbunov, Yi Huang, Haiwang Yu, Jin Huang, Shinjae Yoo, Meifeng Lin, Brett Viren, Yihui Ren</i>, <a href="./papers/2023_UVCGAN_UNetVisionTransformerCycle-consistentGANforUnpairedImage-to-imageTranslation/paper.pdf" target=&ldquo;blank&rdquo;>UVCGAN: UNet Vision Transformer Cycle-consistent GAN for Unpaired Image-to-image Translation</a>, <b><a href="https://wacv2023.thecvf.com/home" target=&ldquo;blank&rdquo;>WACV 2023</a></b>
</p>
<ul>
<li><p><b>Abstract:</b>: Unpaired image-to-image translation has broad applications in art, design, and scientific simulations. One early breakthrough was CycleGAN that emphasizes one-to-one mappings between two unpaired image domains via generative-adversarial networks (GAN) coupled with the cycle-consistency constraint, while more recent works promote one-to-many mapping to boost diversity of the translated images. Motivated by scientific simulation and one-toone
needs, this work revisits the classic CycleGAN framework and boosts its performance to outperform more contemporary models without relaxing the cycle-consistency constraint. To achieve this, we equip the generator with a Vision Transformer (ViT) and employ necessary training and regularization techniques. Compared to previous best-performing models, our model performs better and retains a strong correlation between the original and translated image. An accompanying ablation study shows that both the gradient penalty and self-supervised pre-training are crucial to the improvement. To promote reproducibility and open science, the source code, hyperparameter configurations, and pre-trained model are available at <a href="https://github.com/LS4GAN/uvcgan" target=&ldquo;blank&rdquo;>https://github.com/LS4GAN/uvcgan</a>.
</p>
</li>
<li><p>Figure
</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<a href="./papers/2023_UVCGAN_UNetVisionTransformerCycle-consistentGANforUnpairedImage-to-imageTranslation/figure/figure.png"><img src="./papers/2023_UVCGAN_UNetVisionTransformerCycle-consistentGANforUnpairedImage-to-imageTranslation/figure/figure.png" alt="UVCGAN: UNet Vision Transformer Cycle-consistent GAN for Unpaired Image-to-image Translation" height="345px" style="padding: 0px 0px 0px 60px ;"/></a>&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><i>Yi Huang, Victor Rotaru, Ishanu Chattopadhyay</i>, <a href="./papers/2022_SequenceLikelihoodDivergenceForFastTimeSeriesComparison/paper.pdf" target=&ldquo;blank&rdquo;>Sequence Likelihood Divergence For Fast Time Series Comparison</a>, <b>Knowledge and Information Systems 2022</b>
</p>
<ul>
<li><p><b>Abstract:</b> Comparing and contrasting subtle historical patterns is central to time series analysis. Here we introduce a new approach to quantify deviations in the underlying hidden stochastic generators of sequential discretevalued data streams. The proposed measure is universal in the sense that we can compare data streams without any feature engineering step, and without the need of any hyper-parameters. Our core idea here is the generalization of the Kullback-Leibler (KL) divergence, often used to compare probability distributions, to a notion of divergence between finite-valued ergodic stationary stochastic processes. Using this notion of process divergence, we craft a measure of deviation on finite sample paths which we call the sequence likelihood divergence (SLD) which approximates a metric on the space of the underlying generators within a well-defined class of discrete-valued stochastic processes. We compare the performance of SLD against the state of the art approaches, e.g., dynamic time warping (DTW) with synthetic data, real-world applications with electroencephalogram (EEG) data and in gait recognition, and on diverse time-series classification problems from the University of California, Riverside (UCR) time series classification archive. We demonstrate that the new tool is at par or better in classification accuracy, while being significantly faster in comparable implementations. Released in the publicly domain, we are hopeful that SLD will enhance the standard toolbox used in classification, clustering and inference problems in time series analysis.
</p>
</li>
<li><p>The left figure is an example of the directed weighted graph obtained by analyzing the set of causal states of a stochastic process of Markov order two. The strongly connected component of the graph (marked by solid edges) is a probabilistic finite-state automaton that generates the process. The middle figure is a side-by-side semantic comparison of three time series models, the Markov chain model, the probabilistic finite-state automaton, and the hidden Markov model. The right figure shows convergence of log-likelihood scores to their theoretic values.  
</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<a href="./papers/2022_SequenceLikelihoodDivergenceForFastTimeSeriesComparison/figure/figure.png"><img src="./papers/2022_SequenceLikelihoodDivergenceForFastTimeSeriesComparison/figure/figure.png" alt="Sequence Likelihood Divergence For Fast Time Series Comparison" height="320px" style="padding: 0px 0px 0px 60px ;"/></a>&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><i>Victor Rotaru, Yi Huang, Timmy Li, James Evans, Ishanu Chattopadhyay</i>, <a href="./papers/2022_Event-levelPredictionOfUrbanCrimeRevealsSignatureOfEnforcementBias/paper.pdf" target=&ldquo;blank&rdquo;>Event-level Prediction of Urban Crime Reveals a Signature of Enforcement Bias in US Cities</a>, <a href="./papers/2022_Event-levelPredictionOfUrbanCrimeRevealsSignatureOfEnforcementBias/suppl.pdf" target=&ldquo;blank&rdquo;>(Supplementary Material)</a>, <b><a href="https://www.nature.com/articles/s41562-022-01372-0" target=&ldquo;blank&rdquo;>Nature Human Behaviour</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> Policing efforts to thwart crime typically rely on criminal infraction reports, which implicitly manifest a complex relationship between crime, policing and society. As a result, crime prediction and predictive policing have stirred controversy, with the latest artificial intelligence-based algorithms producing limited insight into the social system of crime. Here we show that, while predictive models may enhance state power through criminal surveillance, they also enable surveillance of the state by tracing systemic biases in crime enforcement. We introduce a stochastic inference algorithm that forecasts crime by learning spatio-temporal dependencies from event reports, with a mean area under the receiver operating characteristic curve of approximately 90% in Chicago for crimes predicted per week within approximately 1000 ft. Such predictions enable us to study perturbations of crime patterns that suggest that the response to increased crime is biased by neighbourhood socio-economic status, draining policy resources from socio-economically disadvantaged areas, as demonstrated in eight major US cities.
</p>
</li>
<li><p>Figure
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><i>Yi Huang, Ishanu Chattopadhyay</i>, <a href="./paper/2021_UniversalRiskPhenotypeOfUSCountiesForFlu-likeTransmissionToImproveCountySpecificCOVID-19IncidenceForecasts/paper.pdf" target=&ldquo;blank&rdquo;>Universal Risk Phenotype of US Counties for Flu-like Transmission to Improve County Specific COVID-19 Incidence Forecasts</a>, <b><a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009363" target=&ldquo;blank&rdquo;>PLOS Computational Biology</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> The spread of a communicable disease is a complex spatio-temporal process shaped by the specific transmission mechanism, and diverse factors including the behavior, socio-economic and demographic properties of the host population. While the key factors shaping transmission of influenza and COVID-19 are beginning to be broadly understood, making precise forecasts on case count and mortality is still difficult. In this study we introduce the concept of a universal geospatial risk phenotype of individual US counties facilitating flu-like transmission mechanisms. We call this the Universal Influenza-like Transmission (UnIT) score, which is computed as an information-theoretic divergence of the local incidence time series from an high-risk process of epidemic initiation, inferred from almost a decade of flu season incidence data gleaned from the diagnostic history of nearly a third of the US population. Despite being computed from the past seasonal flu incidence records, the UnIT score emerges as the dominant factor explaining incidence trends for the COVID-19 pandemic over putative demographic and socio-economic factors. The predictive ability of the UnIT score is further demonstrated via county-specific weekly case count forecasts which consistently outperform the state of the art models throughout the time-line of the COVID-19 pandemic. This study demonstrates that knowledge of past epidemics may be used to chart the course of future ones, if transmission mechanisms are broadly similar, despite distinct disease processes and causative pathogens.
</p>
</li>
<li><p>Figure
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><i>Dmytro Onishchenko, Yi Huang, James van Horne, Peter J. Smith, Michael M. Msall, Ishanu Chattopadhyay</i>, <a href="./papers/2021_ReducedFalsePositivesInAutismScreeningViaDigitalBio-MarkersInferredFromDeepCo-MorbidityPatterns/paper.pdf" target=&ldquo;blank&rdquo;>Reduced False Positives in Autism Screening via Digital Biomarkers Inferred From Deep Comorbidity Patterns</a>, <b><a href="https://www.science.org/doi/10.1126/sciadv.abf0354" target=&ldquo;blank&rdquo;>Science Advances</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> Here, we develop digital biomarkers for autism spectrum disorder (ASD), computed from patterns of past medical encounters, identifying children at high risk with an area under the receiver operating characteristic exceeding 80% from shortly after 2 years of age for either sex, and across two independent patient databases. We leverage uncharted ASD comorbidities, with no requirement of additional blood work, or procedures, to estimate the autism comorbid risk score (ACoR), during the earliest years when interventions are the most effective. ACoR has superior predictive performance to common questionnaire-based screenings and can reduce their current socioeconomic, ethnic, and demographic biases. In addition, we can condition on current screening scores to either halve the state-of-the-art false-positive rate or boost sensitivity to over 60%, while maintaining specificity above 95%. Thus, ACoR can significantly reduce the median diagnostic age, reducing diagnostic delays and accelerating access to evidence-based interventions.
</p>
</li>
<li><p>Figure
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><i>Victor Rotaru, Yi Huang, Ishanu Chattopadhyay</i>, <a href="./papers/2021_Process-awareFastTimeSeriesClusteringAndClassificationBasedOnHiddenStochasticGeneratorsOfPhysicalProcesses/paper.pdf" target=&ldquo;blank&rdquo;>Timesmash: Process-aware Fast Time Series Clustering and Classification</a>, <b><a href="https://sites.google.com/view/aaai-mlps" target=&ldquo;blank&rdquo;>AAAI-MLPS 2021</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> We introduce Timesmash: a comprehensive suite of clustering and classification algorithms and their implementation as a eponymous python package for stochastic time series analysis. We leverage a subclass of hidden Markov model (HMM), called Probabilistic Finite-State Automaton (PFSA), which are used to first model in an unsupervised setting the underlying generative processes for observed data streams, which then aid in carrying out automatic physics or process aware featurization enabling subsequent clustering and classification. The algorithms in this suite consist of the following tools: a) LikelihoodDistance estimating in an unsupervised setting the divergence between ergodic stationary finite valued stochastic processes from the observation of finite and possibly unequal sample paths. b) Featurization algorithms SymbolicDerivative, InferredHMMLikelihood, and ClusteredHMMClassifier, which operate by aiming to recover the underlying hidden generator for the sample paths presented, which then may be used to automatically distill effective features for classification. Our core algorithms require the data streams to take values in a finite alphabet. To extend applicability to continuous-valued time series, a data-driven quantization algorithm, our implementation includes the tool Quantizer that discretizes continuous sequences without the assumption of domain knowledge. We evaluate the performance of the Timesmash algorithms on problems from the
UCR Time Series Classification Archive, and show that we at par or better compared to the state of the art Dynamic Time Warping (DTW) algorithm. In addition, we include brief examples where our unsupervised physical modeling leads to insights not easily obtainable with the current state of the art.
</p>
</li>
<li><p>Figure
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><i>Yi Huang, Yihui Ren, Shinjae Yoo, and Jin Huang</i>, <a href="./papers/2021_EfficientDataCompressionFor3DSparseTPCViaBicephalousConvolutionalAutoencoder/paper.pdf" target=&ldquo;blank&rdquo;>Efficient Data Compression for 3D Sparse TPC via Bicephalous Convolutional Autoencoder</a>, <b><a href="https://www.icmla-conference.org/icmla21/" target=&ldquo;blank&rdquo;>ICMLA 2021</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> Real-time data collection and analysis in large experimental facilities present a great challenge across multiple domains, including high energy physics, nuclear physics, and cosmology. To address this, machine learning (ML)-based methods for real-time data compression have drawn significant attention. However, unlike natural image data, such as CIFAR and ImageNet that are relatively small-sized and continuous, scientific data often come in as three-dimensional (3D) data volumes at high rates with high sparsity (many zeros) and non-Gaussian value distribution. This makes direct application of popular ML compression methods, as well as conventional data compression methods, suboptimal. To address these obstacles, this work introduces a dual-head autoencoder to resolve sparsity and regression simultaneously, called Bicephalous Convolutional AutoEncoder (BCAE). This method shows advantages both in compression fidelity and ratio compared to traditional data compression methods, such as MGARD, SZ, and ZFP. To achieve similar fidelity, the best performer among the traditional methods can reach only half the compression ratio of BCAE. Moreover, a thorough ablation study of the BCAE method shows that a dedicated segmentation decoder improves the reconstruction.
</p>
</li>
<li><p>Figure
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><i>Tingran Gao, Shahab Asoodeh, Yi Huang, James Evens</i>, <a href="./papers/2019_WassersteinSoftLabelPropagationOnHypergraphs/paper.pdf" target=&ldquo;blank&rdquo;>Wasserstein Soft Label Propagation on Hypergraphs: Algorithm and Generalization Error Bounds</a>, <a href="./papers/2019_WassersteinSoftLabelPropagationOnHypergraphs/suppl.pdf" target=&ldquo;blank&rdquo;>(Supplemental Material)</a>, <b><a href="http://www.aaai.org/Conferences/conferences.php" target=&ldquo;blank&rdquo;>AAAI 2019</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> Inspired by recent interests in developing machine learning and data mining algorithms for hypergraphs, here we investigate the semi-supervised learning algorithm of propagating &ldquo;soft labels&rdquo; (e.g. probability distributions, class membership scores) over hypergraphs, by means of optimal transportation. Borrowing insights from Wasserstein propagation on graphs [Solomon et al. 2014], we reformulate the label propagation procedure as a message-passing algorithm, which renders itself naturally to a generalization applicable to hypergraphs through Wasserstein barycenters. Furthermore, in a PAC learning framework, we provide generalization error bounds for propagating 1-dimensional distributions on graphs and hypergraphs using 2-Wasserstein distance, by establishing the algorithmic stability of the proposed semi-supervised learning algorithm. These theoretical results also offer novel insight and deeper understanding about Wasserstein propagation on graphs.
</p>
</li>
<li><p>Figure (a) and (b) compare the classification performance of label propagation v.s. those of AdaBoost, Random forest, and SVM on hypergraphs generated with the stochastic block model over 100 vertices. Figure (c) and (d) compare the classification performance of label propagation v.s. that of SVM on two UCI datastes. 
</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<img src="./figures/hypergraphLabelProp.png" alt="Label Propagation Classification" height="200px" />&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><i>Shahab Asoodeh, Yi Huang, and Ishanu Chattopadhyay</i>, <a href="./papers/2018_ATamper-FreeSemi-UniversalCommunicationSystemForDeletionChannels/paper.pdf" target=&ldquo;blank&rdquo;>A Tamper-Free Semi-Universal Communication System for Deletion Channels</a>, <b><a href="https://cdc2018.ieeecss.org" target=&ldquo;blank&rdquo;>CDC 2018</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> We investigate the problem of reliable communication between two legitimate parties over deletion channels under an active eavesdropping (aka jamming) adversarial model. To this goal, we develop a theoretical framework based on probabilistic finite- state automata to define novel encoding and decoding schemes that ensure small error probability in both message decoding as well as tamper detecting. We then experimentally verify the reliability and tamper-detection property of our scheme.
</p>
</li>
<li><p>The four images on left show how different deletion rates of the channel affect the space of M2 machines&ndash;the larger the deletion rate, the closer the resulting machine to being a single-state machine. The four images on the right show sets of 10 and 20 machines chosen by a hill-climbing algorithm to represent the messages, how they are affected by deletion, and how the error rate of recoving the message decreases with increasing sequence lengths.  
</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<img src="./figures/temper-free_combined.jpg" alt="Temper-free with PFSA" height="150px" />&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><i>Yi Huang, Mano Vikash Janardhanan, and Lev Reyzin</i>, <a href="./papers/2017_NetworkConstructionWithOrderedConstraints/paper.pdf" target=&ldquo;blank&rdquo;>Network Construction with Ordered Constraints</a>, <b><a href="http://fsttcs.org/archives/2017/" target=&ldquo;blank&rdquo;>FSTTCS 2017</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> In this paper, we study the problem of constructing a network by observing ordered connectivity constraints, which we define herein. These ordered constraints are made to capture realistic properties of real-world problems that are not reflected in previous, more general models. We give hardness of approximation results and nearly-matching upper bounds for the offline problem, and we study the online problem in both general graphs and restricted sub-classes. In the online problem, for general graphs, we give exponentially better upper bounds than exist for algorithms for general connectivity problems. For the restricted classes of stars and paths we are able to find algorithms with optimal competitive ratios, the latter of which involve analysis using a potential function defined over PQ-trees.
</p>
</li>
<li><p>The following figures show patterns and their replacements of the PQ-trees that show up in the analysis of the competitive ratio of path. 
</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<img src="./figures/ordered-constraints_pq-tree_combined.jpg" alt="Network Construction with Ordered Constraints" height="165px" />&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><i>Benjamin Fish, Yi Huang, and Lev Reyzin</i>, <a href="./papers/2016_RecoveringSocialNetworksByObservingVotes/paper.pdf" target=&ldquo;blank&rdquo;>Recovering Social Networks by Observing Votes</a>, <b><a href="https://sis.smu.edu.sg/aamas2016" target=&ldquo;blank&rdquo;>AAMAS 2016</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> We investigate how to reconstruct social networks from voting data. In particular, given a voting model that considers social network structure, we aim to find the network that best explains the agents&rsquo; votes. We study two plausible voting models, one edge-centric and the other vertex-centric. For these models, we give algorithms and lower bounds, characterizing cases where network recovery is possible and where it is computationally difficult. We also test our algorithms on United States Senate data. Despite the similarity of the two models, we show that their respective network recovery problems differ in complexity and involve distinct algorithmic challenges. Moreover, the networks produced when working under these models can also differ significantly. These results indicate that great care should be exercised when choosing a voting model for network recovery tasks.
</p>
</li>
<li><p>The three images on the left are the networks we recovered using the edge-centric model on three Senates, and the three images on the right are those using the vertex-centric model on the same three Senates. 
</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<img src="./figures/voting-network_combined.jpg" alt="Voting Network" height="175px" />&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><i>Yi Huang, Brian Powers, and Lev Reyzin</i>, <a href="./papers/2015_TrainingTimeOptimizationOfABudgetedBooster/paper.pdf" target=&ldquo;blank&rdquo;>Training-Time Optimization of a Budgeted Booster</a>, <b><a href="https://ijcai-15.org" target=&ldquo;blank&rdquo;>IJCAI2015</a></b>
</p>
<ul>
<li><p><b>Abstract:</b> We consider the problem of feature-efficient prediction &ndash; a setting where features have costs and the learner is limited by a budget constraint on the total cost of the features it can examine in test time. We focus on solving this problem with boosting by optimizing the choice of base learners in the training phase and stopping the boosting process when the learner’s budget runs out. We experimentally show that our method improves upon the boosting approach AdaBoostRS [Reyzin, 2011] and in many cases also outperforms the recent algorithm SpeedBoost [Grubb and Bagnell, 2012]. We provide a theoretical justication for our optimization method via the margin bound. We also experimentally show that our method outperforms pruned decision trees, a natural budgeted classifier.
</p>
</li>
<li><p>The image on the right shows the comparison of error rates v.s. costs of methods we metion in this paper on three datasets from the UCI machine learning repository, and the image on the right is that for Yahoo Webscop set 2 where the cost is real CPU time.
</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<img src="./figures/budgeted-booster_combined.jpg" alt="Budgeted Booster" height="250px" />&nbsp;</td>
<td align="left"></td></tr></table>
<h1>Ph.D. Theses: <a href="./papers/2017_PhDThesis_ProblemsInLearningUnderLimitedResourcesAndInformation.pdf" target=&ldquo;blank&rdquo;>Problems in Learning under Limited Resources and Information</a></h1>
<div id="footer">
<div id="footer-text">
Page generated 2022-12-20 10:08:57 Eastern Standard Time, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript"></script>
<script type="text/javascript">_uacct = "UA-0000000-0"; urchinTracker();</script>
</body>
</html>
